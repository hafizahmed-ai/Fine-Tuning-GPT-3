{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Data to Small Samples of Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "amazon_df = pd.read_csv('amazon_qna.csv')\n",
    "training_amazon_df = amazon_df.iloc[0:200]\n",
    "validation_amazon_df = amazon_df.iloc[200:225]\n",
    "\n",
    "training_amazon_df.to_csv('amazon_qna_training.csv', index=False)\n",
    "validation_amazon_df.to_csv('amazon_qna_validation.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Training and Validation CSV to JSONL format required to Fine Tune OpenAI GPT-3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'amazon_qna_training.csv' has been converted and saved to 'amazon_qna_training.jsonl'.\n",
      "Data from 'amazon_qna_validation.csv' has been converted and saved to 'amazon_qna_validation.jsonl'.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "input_file = 'amazon_qna_training.csv'\n",
    "output_file = 'amazon_qna_training.jsonl'\n",
    "\n",
    "# Read CSV file and create JSONL data\n",
    "jsonl_data = []\n",
    "\n",
    "with open(input_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        question = row['Question']\n",
    "        answer = row['Answer']\n",
    "        json_object = {\n",
    "            \"prompt\": question + \" ->\",\n",
    "            \"completion\": answer + \"\\n\"\n",
    "        }\n",
    "        jsonl_data.append(json.dumps(json_object))\n",
    "\n",
    "# Write JSONL data to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as jsonlfile:\n",
    "    for entry in jsonl_data:\n",
    "        jsonlfile.write(f\"{entry}\\n\")\n",
    "\n",
    "print(f\"Data from '{input_file}' has been converted and saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "\n",
    "input_file = 'amazon_qna_validation.csv'\n",
    "output_file = 'amazon_qna_validation.jsonl'\n",
    "\n",
    "# Read CSV file and create JSONL data\n",
    "jsonl_data = []\n",
    "\n",
    "with open(input_file, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        question = row['Question']\n",
    "        answer = row['Answer']\n",
    "        json_object = {\n",
    "            \"prompt\": question + \" ->\",\n",
    "            \"completion\": answer + \"\\n\"\n",
    "        }\n",
    "        jsonl_data.append(json.dumps(json_object))\n",
    "\n",
    "# Write JSONL data to the output file\n",
    "with open(output_file, 'w', encoding='utf-8') as jsonlfile:\n",
    "    for entry in jsonl_data:\n",
    "        jsonlfile.write(f\"{entry}\\n\")\n",
    "\n",
    "print(f\"Data from '{input_file}' has been converted and saved to '{output_file}'.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload Training and Validation JSONL Data to OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file response {\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-cZgZ3qCaQDkdJH9HCPD8kFbN\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 50369,\n",
      "  \"created_at\": 1692104656,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "validation file response {\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-Xuj5TGFOlHmG3Q31da4eQueN\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 6381,\n",
      "  \"created_at\": 1692104657,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "file = 'amazon_qna_training.jsonl'\n",
    "response = openai.File.create(purpose='fine-tune', file=open(file, 'rb'))\n",
    "training_file_id = response['id']\n",
    "print(f'training file response {response}')\n",
    "\n",
    "file = 'amazon_qna_validation.jsonl'\n",
    "response = openai.File.create(purpose='fine-tune', file=open(file, 'rb'))\n",
    "validation_file_id = response['id']\n",
    "print(f'validation file response {response}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tune GPT-3 Model with JSONL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_args = {\n",
    "\t\"training_file\": training_file_id,\n",
    "\t\"validation_file\": validation_file_id,\n",
    "\t\"model\": \"davinci\",\n",
    "\t\"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "\n",
    "response = openai.FineTune.create(**create_args)\n",
    "job_id = response[\"id\"]\n",
    "status = response[\"status\"]\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor Fine Tuning Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ft-tDJrE3lXakF5pIYZJ04iwztd\n",
      "2023-08-14 22:59:24 Created fine-tune: ft-tDJrE3lXakF5pIYZJ04iwztd\n",
      "2023-08-14 23:01:09 Fine-tune costs $4.80\n",
      "2023-08-14 23:01:09 Fine-tune enqueued. Queue number: 0\n",
      "2023-08-14 23:01:11 Fine-tune started\n",
      "2023-08-14 23:03:59 Completed epoch 1/15\n",
      "2023-08-14 23:05:08 Completed epoch 2/15\n",
      "2023-08-14 23:06:16 Completed epoch 3/15\n",
      "2023-08-14 23:07:25 Completed epoch 4/15\n",
      "2023-08-14 23:08:33 Completed epoch 5/15\n",
      "2023-08-14 23:09:41 Completed epoch 6/15\n",
      "2023-08-14 23:10:50 Completed epoch 7/15\n",
      "2023-08-14 23:11:59 Completed epoch 8/15\n",
      "2023-08-14 23:13:08 Completed epoch 9/15\n",
      "2023-08-14 23:14:16 Completed epoch 10/15\n",
      "2023-08-14 23:15:25 Completed epoch 11/15\n",
      "2023-08-14 23:16:32 Completed epoch 12/15\n",
      "2023-08-14 23:17:40 Completed epoch 13/15\n",
      "2023-08-14 23:18:49 Completed epoch 14/15\n",
      "2023-08-14 23:19:56 Completed epoch 15/15\n",
      "2023-08-14 23:20:35 Uploaded model: davinci:ft-personal-2023-08-14-18-20-34\n",
      "2023-08-14 23:20:36 Uploaded result file: file-aDBAKvFsIuB9iML5n1m1Mgd3\n",
      "2023-08-14 23:20:37 Fine-tune succeeded\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "\n",
    "job_id = 'ft-tDJrE3lXakF5pIYZJ04iwztd'\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "\tstatus = openai.FineTune.retrieve(job_id).status\n",
    "\tprint(f\"Stream interrupted. Job is still {status}.\")\n",
    "\treturn\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = openai.FineTune.stream_events(job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "    \tprint(f'{datetime.datetime.fromtimestamp(event[\"created_at\"])} {event[\"message\"]}')\n",
    "\n",
    "except Exception:\n",
    "\tprint(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track Fine Tuning Job Status on OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune job ft-tDJrE3lXakF5pIYZJ04iwztd finished with status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 1 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "job_id = 'ft-tDJrE3lXakF5pIYZJ04iwztd'\n",
    "\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f'Job not in terminal status: {status}. Waiting.')\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(2)\n",
    "        status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "        print(f'Status: {status}')\n",
    "else:\n",
    "\tprint(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = openai.FineTune.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Fine Tuned Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davinci:ft-personal-2023-08-14-18-20-34\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the finetuned model\n",
    "fine_tuned_model = result['data'][0]['fine_tuned_model']\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference on Fine Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think they are about the same, and it does not need to be cleaned\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"Is this louder/quiter than the HWM450? Does it need to be cleaned more often? ->\"\n",
    "answer = openai.Completion.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer['choices'][0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42f2af155f06eb64a61bda347fc1d4082f79825bde18a1adde3b13622bea600e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
